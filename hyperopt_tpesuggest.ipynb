{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, LSTM, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import datetime as dt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'units': hp.choice('units', [1,4,8,16,32,64,128,256,512]),\n",
      "        'activation': hp.choice('activation', ['sigmoid', 'tanh', 'relu', 'linear']),\n",
      "        'use_bias': hp.choice('use_bias', [False, True]),\n",
      "        'lr': hp.uniform('lr', 0,10),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: \n",
      "  3: import datetime as dt\n",
      "  4: import numpy as np\n",
      "  5: import pandas as pd\n",
      "  6: from sklearn.preprocessing import MinMaxScaler\n",
      "  7: \n",
      "  8: df = pd.read_json('df.json', orient='split')\n",
      "  9: df = pd.DataFrame(df.eth_close.copy())\n",
      " 10: df = df[557:]\n",
      " 11: \n",
      " 12: scaler_1 = MinMaxScaler(feature_range=(0,1))\n",
      " 13: df_scaled = scaler_1.fit_transform(df.values)\n",
      " 14: df = pd.DataFrame(df_scaled).set_index(df.index.values)\n",
      " 15: \n",
      " 16: df.columns = ['unshifted']\n",
      " 17: n_shifts=1\n",
      " 18: df_shifted = df.copy()\n",
      " 19: for i in range(n_shifts):\n",
      " 20:     df = pd.concat([df, df_shifted.shift(i+1)], axis=1)\n",
      " 21:     df.dropna(axis=0, inplace=True)\n",
      " 22: \n",
      " 23: cols = list(df.columns)[1:]\n",
      " 24: for i, col in enumerate(cols):\n",
      " 25:     cols[i] = 'shift_{}'.format(i+1)\n",
      " 26: cols = [df.columns[0]] + cols\n",
      " 27: df.columns = cols\n",
      " 28: \n",
      " 29: data = df.loc[:, ~df.columns.isin(['unshifted'])]\n",
      " 30: X = np.array(data).reshape(data.shape[0], data.shape[1], 1)\n",
      " 31: y = df.unshifted\n",
      " 32: \n",
      " 33: \n",
      " 34: \n",
      " 35: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3:     \n",
      "  4:     test_size = 60\n",
      "  5:     X_train, y_train = X[:-test_size], y[:-test_size]\n",
      "  6:     X_test, y_test = X[-test_size:], y[-test_size:]\n",
      "  7:     \n",
      "  8:     model = Sequential()\n",
      "  9:     model.add(LSTM(\n",
      " 10:         units=space['units'],\n",
      " 11:         activation=space['activation'],\n",
      " 12:         use_bias=space['use_bias'],\n",
      " 13:         input_shape=(X_train.shape[1], X_train.shape[2])))\n",
      " 14:     model.add(Dense(1))\n",
      " 15:     \n",
      " 16:     optimizer = Adadelta(lr=space['lr'])\n",
      " 17:     \n",
      " 18:     model.compile(loss='mean_squared_error',\n",
      " 19:                   optimizer=optimizer,\n",
      " 20:                   metrics=['mse'])\n",
      " 21: \n",
      " 22:     model.fit(X_train, y_train,\n",
      " 23:               epochs=10,\n",
      " 24:               verbose=0,\n",
      " 25:               validation_data=(X_test, y_test))\n",
      " 26:     score, mse = model.evaluate(X_test, y_test, verbose=0)\n",
      " 27:     print('test mse: {}'.format(mse))\n",
      " 28:     return {'loss': mse, 'status': STATUS_OK, 'model': model}\n",
      " 29: \n",
      "test mse: 0.00030304858228191733\n",
      "test mse: 0.0002602030358199651\n",
      "test mse: 0.00031774773572882016\n",
      "test mse: 0.0001056959391765607\n",
      "test mse: 0.0014738778195654352\n",
      "test mse: 0.18857745826244354\n",
      "test mse: 0.012205154386659462\n",
      "test mse: 0.0025388044615586598\n",
      "test mse: 0.00010215789079666137\n",
      "test mse: 0.012293308538695176\n",
      "test mse: 0.0020342291798442604\n",
      "test mse: 0.00250017784225444\n",
      "test mse: 0.00010337354566824312\n",
      "test mse: 0.001300178817473352\n",
      "test mse: 0.00018774956988636403\n",
      "test mse: 0.013817313189307848\n",
      "test mse: 0.00010129478032467887\n",
      "test mse: 0.0005885129988503953\n",
      "test mse: 0.015488208706180255\n",
      "test mse: 0.024242991209030153\n",
      "test mse: 0.00021557802295622727\n",
      "test mse: 0.00032170249226813515\n",
      "test mse: 0.0001281117045436986\n",
      "test mse: 0.006482975774755081\n",
      "test mse: 0.00115526233954976\n",
      "Evalutation of best performing model:\n",
      "606/606 [==============================] - 0s 26us/step\n",
      "[0.0005456121277885139, 0.0005456121277885139]\n",
      "{'activation': 1, 'lr': 8.918369461802055, 'units': 1, 'use_bias': 1}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "def data():\n",
    "    \n",
    "    import datetime as dt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    df = pd.read_json('df.json', orient='split')\n",
    "    df = pd.DataFrame(df.eth_close.copy())\n",
    "    df = df[557:]\n",
    "    \n",
    "    scaler_1 = MinMaxScaler(feature_range=(0,1))\n",
    "    df_scaled = scaler_1.fit_transform(df.values)\n",
    "    df = pd.DataFrame(df_scaled).set_index(df.index.values)\n",
    "\n",
    "    df.columns = ['unshifted']\n",
    "    n_shifts=1\n",
    "    df_shifted = df.copy()\n",
    "    for i in range(n_shifts):\n",
    "        df = pd.concat([df, df_shifted.shift(i+1)], axis=1)\n",
    "        df.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    cols = list(df.columns)[1:]\n",
    "    for i, col in enumerate(cols):\n",
    "        cols[i] = 'shift_{}'.format(i+1)\n",
    "    cols = [df.columns[0]] + cols\n",
    "    df.columns = cols\n",
    "\n",
    "    data = df.loc[:, ~df.columns.isin(['unshifted'])]\n",
    "    X = np.array(data).reshape(data.shape[0], data.shape[1], 1)\n",
    "    y = df.unshifted\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def model(X, y):\n",
    "    \n",
    "    test_size = 60\n",
    "    X_train, y_train = X[:-test_size], y[:-test_size]\n",
    "    X_test, y_test = X[-test_size:], y[-test_size:]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        units={{choice([1,4,8,16,32,64,128,256,512])}},\n",
    "        activation={{choice(['sigmoid', 'tanh', 'relu', 'linear'])}},\n",
    "        use_bias={{choice([False, True])}},\n",
    "        input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    optimizer = Adadelta(lr={{uniform(0,10)}})\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              epochs=10,\n",
    "              verbose=0,\n",
    "              validation_data=(X_test, y_test))\n",
    "    score, mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('test mse: {}'.format(mse))\n",
    "    return {'loss': mse, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "X, y = data()\n",
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=25,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='hyperopt_tpesuggest')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X, y))\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 0:0, 1:0.01, 2:0.02, 3:0.05, 4:0.1\n",
    "# activation 0:'sigmoid', 1:'tanh', 2:'relu', 3:'linear'\n",
    "# units 0:1, 1:4, 2:8, 3:16, 4:32, 5:64, 6:128, 7:256, 8:512\n",
    "# use_bias 0: False, 1: True\n",
    "\n",
    "#optimizer = Adamax(lr={{uniform(0,1)}})\n",
    "# defaults\n",
    "# SGD lr 0.01 SKIP always high RMSE\n",
    "# RMSprop lr 0.001\n",
    "# Adam lr 0.001\n",
    "# Adamax lr 0.002\n",
    "\n",
    "# keras recommends leaving alone:\n",
    "# Adagrad lr 0.001\n",
    "# Adadelta lr 1.0\n",
    "# Nadam lr 0.002"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
